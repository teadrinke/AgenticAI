{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584a0ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1affc6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated, List, Optional, Dict, TypedDict\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a22f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "repl = PythonREPL()\n",
    "\n",
    "os.makedirs(\"temp\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f248447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def scrape_webpages(urls: List[str]) -> str:\n",
    "    '''User requests and bs4 to scrape the provided webpages for detailed information'''\n",
    "    loader = WebBaseLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"<Document name={doc.metadata['source']}>\\n{doc.page_content}\\n</Document>\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def create_outline(\n",
    "    points: Annotated[List[str], \"List of main points or sections\"],\n",
    "    file_name: Annotated[str, \"File path to save the outline\"]\n",
    ") -> Annotated[str, \"Path of the saved outline file\"]:\n",
    "    '''Create and save an outline'''\n",
    "    file_to_use = os.path.join(os.getcwd(), \"temp\", file_name)\n",
    "    with open(file_to_use, \"w\") as f:\n",
    "        for i, point in enumerate(points):\n",
    "            f.write(f\"{i+1}. {point}\\n\")\n",
    "    return f\"Outline saved to {file_to_use}\"\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to read the document from\"],\n",
    "    start: Annotated[Optional[object], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[object], \"The end line. Default is None\"] = None\n",
    "):\n",
    "    '''Read the specified document. Accepts integers or strings that represent integers.'''\n",
    "    def to_int_or_none(v: Optional[object]) -> Optional[int]:\n",
    "        if v is None:\n",
    "            return None\n",
    "        # allow ints unchanged\n",
    "        if isinstance(v, int):\n",
    "            return v\n",
    "        # allow numeric strings like \"0\", \" 3 \"\n",
    "        if isinstance(v, str):\n",
    "            s = v.strip()\n",
    "            if s == \"\" or s.lower() == \"none\" or s.lower() == \"null\":\n",
    "                return None\n",
    "            if s.isdigit() or (s.startswith('-') and s[1:].isdigit()):\n",
    "                return int(s)\n",
    "            # try float-like but castable to int (not recommended but safe)\n",
    "            try:\n",
    "                f = float(s)\n",
    "                return int(f)\n",
    "            except Exception:\n",
    "                raise ValueError(f\"Cannot coerce start/end value to int: {v!r}\")\n",
    "        raise ValueError(f\"Unsupported type for start/end: {type(v)}\")\n",
    "\n",
    "    start_i = to_int_or_none(start)\n",
    "    end_i = to_int_or_none(end)\n",
    "\n",
    "    file_to_use = os.path.join(os.getcwd(), \"temp\", file_name)\n",
    "    with open(file_to_use, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    if start_i is None:\n",
    "        start_i = 0\n",
    "    if end_i is None:\n",
    "        end_i = len(lines)\n",
    "    # safety clamps\n",
    "    start_i = max(0, start_i)\n",
    "    end_i = min(len(lines), end_i)\n",
    "    if start_i > end_i:\n",
    "        return f\"Invalid range: start ({start_i}) > end ({end_i}).\"\n",
    "\n",
    "    return \"\\n\".join(lines[start_i:end_i])\n",
    "\n",
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"The content to write to the document\"],\n",
    "    file_name: Annotated[str, \"File path to save the document to\"]\n",
    "):\n",
    "    '''Create and save a text document'''\n",
    "    file_to_use = os.path.join(os.getcwd(), \"temp\", file_name)\n",
    "    with open(file_to_use, \"w\") as f:\n",
    "        f.write(content)\n",
    "    return f\"Document saved to {file_name}\"\n",
    "\n",
    "@tool\n",
    "def edit_document(\n",
    "    file_name: Annotated[str, \"File path to read the document from and save the edited document to\"],\n",
    "    insert: Annotated[Dict[int, str], \"A dictionary where keys are line numbers and values are the text to insert at those lines\"]\n",
    "):\n",
    "    '''Edit a document by inserting text at specified line numbers'''\n",
    "    file_to_use = os.path.join(os.getcwd(), \"temp\", file_name)\n",
    "    with open(file_to_use, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    sorted_inserts = sorted(insert.items())\n",
    "    for line_num, text in sorted_inserts:\n",
    "        if 1 <= line_num <= len(lines):\n",
    "            lines.insert(line_num - 1, text + \"\\n\")\n",
    "        else:\n",
    "            return f\"Line number {line_num} is out of range for the document with {len(lines)} lines.\"\n",
    "    with open(file_to_use, \"w\") as f:\n",
    "        f.writelines(lines)\n",
    "    return f\"Document edited and saved to {file_name}\"\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "        code: Annotated[str, \"Python code to execute to generate your chart\"]\n",
    "):\n",
    "    '''Use this to execute python code. If you want to see the output of any value,\n",
    "    you should print it with `print(...)`. This is visible to the user'''\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Error executing code: {repr(e)}\"\n",
    "    return f\"Successfully executed: \\n ```python\\n{code}\\n```\\n Stdout: {result}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c826444",
   "metadata": {},
   "source": [
    "Define the supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01433b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "def make_supervisor_node(llm: BaseChatModel, members: List[str]):\n",
    "    options = [\"FINISH\"] + members\n",
    "    system_prompt = (\n",
    "        \"You are a supervisor tasked with managing a conversation between the\"\n",
    "        f\" following workers: {members}. Given the following user request,\"\n",
    "        \" respond with the worker to act next, each worker will perform a\"\n",
    "        \" task and respond with their results and status. When finished,\"\n",
    "        \" respond with FINISH.\"\n",
    "    )\n",
    "    class Router(TypedDict):\n",
    "        next: str\n",
    "\n",
    "    def supervisor(state: State) -> Command[str]:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt}\n",
    "        ] + state[\"messages\"]\n",
    "\n",
    "        response = llm.with_structured_output(Router).invoke(messages)\n",
    "        goto = response[\"next\"]\n",
    "\n",
    "        if goto not in options:\n",
    "            raise ValueError(f\"Invalid route: {goto}\")\n",
    "        \n",
    "        if goto == \"FINISH\":\n",
    "            return Command(goto=END, update={\"next\": \"FINISH\"})\n",
    "        return Command(goto=goto, update={\"next\": goto})\n",
    "    \n",
    "    return supervisor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c5f12",
   "metadata": {},
   "source": [
    "Research Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d9194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da55ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_tool: <class 'function'> search search\n",
      "web_scrape_tool: <class 'function'> web_scraper web_scraper\n",
      "search_tool: search search\n",
      "web_scrape_tool: web_scraper web_scraper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_9272\\2182689904.py:77: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  search_agent = create_react_agent(llm, tools=[search_tool])\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_9272\\2182689904.py:79: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  web_scraper_agent = create_react_agent(llm, tools=[web_scrape_tool])\n"
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "import uuid\n",
    "\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"moonshotai/kimi-k2-instruct-0905\",model_provider=\"groq\")\n",
    "tavily_tool = TavilySearch(max_results=3)\n",
    "\n",
    "# Put this in a fresh cell and run it BEFORE you call create_react_agent(...)\n",
    "import builtins, functools, inspect, types\n",
    "\n",
    "# ensure uuid is available to any evaluated code\n",
    "import uuid\n",
    "builtins.uuid = uuid\n",
    "\n",
    "def underlying_callable_of(tool_obj):\n",
    "    \"\"\"\n",
    "    Return a Python callable for 'tool_obj':\n",
    "    - If it's a plain function, return it.\n",
    "    - If it's an object with a callable .run or .__call__, return that.\n",
    "    - If it's a framework StructuredTool/BaseTool instance, try .run or .invoke or .__call__.\n",
    "    - Otherwise return None.\n",
    "    \"\"\"\n",
    "    # plain function\n",
    "    if isinstance(tool_obj, types.FunctionType):\n",
    "        return tool_obj\n",
    "    # bound method\n",
    "    if inspect.ismethod(tool_obj):\n",
    "        return tool_obj\n",
    "    # callable objects with __call__\n",
    "    if callable(tool_obj) and hasattr(tool_obj, \"__call__\") and not isinstance(tool_obj, type):\n",
    "        # But we still prefer an explicit .run if present (framework pattern)\n",
    "        if hasattr(tool_obj, \"run\") and callable(getattr(tool_obj, \"run\")):\n",
    "            return getattr(tool_obj, \"run\")\n",
    "        return tool_obj.__call__\n",
    "    # framework-wrapped tools: try .run or .invoke (common patterns)\n",
    "    for attr in (\"run\", \"invoke\", \"__call__\"):\n",
    "        if hasattr(tool_obj, attr) and callable(getattr(tool_obj, attr)):\n",
    "            return getattr(tool_obj, attr)\n",
    "    return None\n",
    "\n",
    "def make_named_tool(name: str, func_or_tool):\n",
    "    \"\"\"\n",
    "    Return a proper function object exposing __name__ and .name for LangGraph.\n",
    "    If func_or_tool is an object with a .run/.invoke method, wrap that method.\n",
    "    \"\"\"\n",
    "    fn = underlying_callable_of(func_or_tool)\n",
    "    if fn is None:\n",
    "        raise TypeError(f\"Cannot extract callable from {func_or_tool!r}\")\n",
    "    @functools.wraps(fn)\n",
    "    def tool_fn(*args, **kwargs):\n",
    "        return fn(*args, **kwargs)\n",
    "    tool_fn.__name__ = name\n",
    "    tool_fn.name = name\n",
    "    return tool_fn\n",
    "\n",
    "# Build wrappers or reuse existing tool objects depending on what you have.\n",
    "# For TavilySearch (third-party), use its .run / .__call__ as underlying callable:\n",
    "search_tool = make_named_tool(\"search\", tavily_tool)\n",
    "\n",
    "# For scrape_webpages: your function is decorated with @tool; underlying_callable_of will find .run or .invoke.\n",
    "# But for many @tool implementations the object *is* a StructuredTool that the framework can accept directly.\n",
    "# So prefer passing the original object if it is already a framework tool type.\n",
    "scrape_callable = underlying_callable_of(scrape_webpages)\n",
    "if scrape_callable is None:\n",
    "    # fallback: use the object itself (maybe it's a BaseTool subclass that create_react_agent accepts)\n",
    "    web_scrape_tool = scrape_webpages\n",
    "else:\n",
    "    # create a named wrapper that exposes __name__ etc.\n",
    "    web_scrape_tool = make_named_tool(\"web_scraper\", scrape_webpages)\n",
    "\n",
    "# Debug prints to confirm what we will pass\n",
    "print(\"search_tool:\", type(search_tool), getattr(search_tool, \"__name__\", None), getattr(search_tool, \"name\", None))\n",
    "print(\"web_scrape_tool:\", type(web_scrape_tool), getattr(web_scrape_tool, \"__name__\", None), getattr(web_scrape_tool, \"name\", None))\n",
    "\n",
    "# Now create agents with those tool objects (the objects are either functions or framework-compatible objects)\n",
    "search_agent = create_react_agent(llm, tools=[search_tool])\n",
    "# If web_scrape_tool is a raw framework tool object, pass it directly\n",
    "web_scraper_agent = create_react_agent(llm, tools=[web_scrape_tool])\n",
    "\n",
    "# Recreate your nodes if needed, then include the same tool objects in invoke()\n",
    "# e.g.\n",
    "# response = research_graph.invoke({\"messages\":[message]}, tools=[search_tool, web_scrape_tool])\n",
    "\n",
    "# sanity checks\n",
    "print(\"search_tool:\", getattr(search_tool, \"__name__\", None), getattr(search_tool, \"name\", None))\n",
    "print(\"web_scrape_tool:\", getattr(web_scrape_tool, \"__name__\", None), getattr(web_scrape_tool, \"name\", None))\n",
    "def search_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\": [HumanMessage(content = result[\"messages\"][-1].content, name=\"search\")\n",
    "            ]\n",
    "        },\n",
    "        goto = \"supervisor\"\n",
    "    )\n",
    "\n",
    "#web_scraper_agent = create_react_agent(llm, tools = [scrape_webpages])\n",
    "def web_scraper_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = web_scraper_agent.invoke(state)\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\": [HumanMessage(content = result[\"messages\"][-1].content, name=\"web_scraper\")\n",
    "            ]\n",
    "        },\n",
    "        goto = \"supervisor\"\n",
    "    )\n",
    "\n",
    "research_supervisor_node = make_supervisor_node(llm, members=[\"search\", \"web_scraper\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282fcd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "\n",
    "research_builder = StateGraph(State)\n",
    "research_builder.add_node(\"supervisor\", research_supervisor_node)\n",
    "research_builder.add_node(\"search\", search_node)\n",
    "research_builder.add_node(\"web_scraper\", web_scraper_node)\n",
    "\n",
    "research_builder.add_edge(START, \"supervisor\")\n",
    "research_graph = research_builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076c552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_tool name: search __name__: search\n",
      "web_scrape_tool name: web_scraper __name__: web_scraper\n"
     ]
    }
   ],
   "source": [
    "print(\"search_tool name:\", getattr(search_tool, \"name\", None), \"__name__:\", getattr(search_tool, \"__name__\", None))\n",
    "print(\"web_scrape_tool name:\", getattr(web_scrape_tool, \"name\", None), \"__name__:\", getattr(web_scrape_tool, \"__name__\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f6a538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can answer this directly without needing to use the search tool. The capital of New Zealand is **Wellington**.\n"
     ]
    }
   ],
   "source": [
    "# Build a minimal fake State object like the supervisor would pass:\n",
    "fake_state = State(messages=[{\"role\":\"system\",\"content\":\"...your system...\"}, {\"role\":\"user\",\"content\":\"What is the capital of New Zealand?\"}], next=\"search\")\n",
    "# Directly invoke the search_agent (this shows what it tries to call)\n",
    "agent_result = search_agent.invoke(fake_state)\n",
    "print(agent_result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0318b4",
   "metadata": {},
   "source": [
    "*Writing Team*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc13fe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_9272\\1591720967.py:1: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  doc_writer_agent = create_react_agent(\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_9272\\1591720967.py:21: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  note_taking_agent = create_react_agent(\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_9272\\1591720967.py:41: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  chart_generating_agent = create_react_agent(\n"
     ]
    }
   ],
   "source": [
    "doc_writer_agent = create_react_agent(\n",
    "    llm, \n",
    "    tools = [write_document, edit_document, read_document],\n",
    "    prompt = (\n",
    "        \"You can read, write and edit documents based on note taker's outlines. \"\n",
    "        \"Don't ask follow up questions\"\n",
    "    )\n",
    ")\n",
    "\n",
    "def doc_writing_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = doc_writer_agent.invoke(state)\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                HumanMessage(content = result[\"messages\"][-1].content, name=\"doc_writer\")\n",
    "            ]\n",
    "        },\n",
    "        goto = \"supervisor\",\n",
    "    )\n",
    "\n",
    "note_taking_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools = [create_outline, read_document],\n",
    "    prompt = (\n",
    "        \"You can read documents and create outlines for the document writer.\"\n",
    "        \"Don't ask follow up questions.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "def note_taking_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = note_taking_agent.invoke(state)\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                HumanMessage(content = result[\"messages\"][-1].content, name=\"note_taker\")\n",
    "            ]\n",
    "        },\n",
    "        goto = \"supervisor\",\n",
    "    )\n",
    "\n",
    "chart_generating_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools = [read_document, python_repl_tool],\n",
    "\n",
    ")\n",
    "\n",
    "def chart_generating_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = chart_generating_agent.invoke(state)\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                HumanMessage(content = result[\"messages\"][-1].content, name=\"chart_generator\")\n",
    "            ]\n",
    "        },\n",
    "        goto = \"supervisor\",\n",
    "    )\n",
    "\n",
    "doc_writing_supervisor = make_supervisor_node(llm, members=[\"note_taker\", \"doc_writer\", \"chart_generator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44bb21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "writing_builder = StateGraph(State)\n",
    "writing_builder.add_node(\"supervisor\", doc_writing_supervisor)\n",
    "writing_builder.add_node(\"note_taker\", note_taking_node)\n",
    "writing_builder.add_node(\"doc_writer\", doc_writing_node)\n",
    "writing_builder.add_node(\"chart_generator\", chart_generating_node)\n",
    "\n",
    "writing_builder.add_edge(START, \"supervisor\")\n",
    "writing_graph = writing_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "454944e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'doc_writer'}}\n",
      "---\n",
      "{'doc_writer': {'messages': [HumanMessage(content='I\\'ve created both the outline and the poem about dogs. The outline provides a structured approach to celebrating dogs through their history, characteristics, personality traits, daily life, and deeper meaning. \\n\\nThe poem \"Ode to Dogs\" is a six-part poem that follows this structure, written in rhyming verse that captures the special relationship between humans and dogs, their various qualities, and the profound impact they have on our lives. Both files have been saved for your reference.', additional_kwargs={}, response_metadata={}, name='doc_writer', id='d8f06a04-a812-4abe-880d-455a2f99ae78')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in writing_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Write an outline for a poem about dogs and after that write the poem itself and store it\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\"recursion_limit\": 30}\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8903068",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_supervisor_node = make_supervisor_node(llm, members=[\"research_team\", \"writing_team\"])\n",
    "\n",
    "def call_research_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = research_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\": [HumanMessage(content = response[\"messages\"][-1].content, name=\"research_team\")]\n",
    "        },\n",
    "        goto = \"supervisor\"\n",
    "    )\n",
    "\n",
    "def call_writing_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = writing_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\": [HumanMessage(content = response[\"messages\"][-1].content, name=\"writing_team\")]\n",
    "        },\n",
    "        goto = \"supervisor\"\n",
    "    )\n",
    "\n",
    "\n",
    "super_builder = StateGraph(State)\n",
    "super_builder.add_node(\"supervisor\", teams_supervisor_node)\n",
    "super_builder.add_node(\"research_team\", call_research_team)\n",
    "super_builder.add_node(\"writing_team\", call_writing_team)\n",
    "\n",
    "super_builder.add_edge(START, \"supervisor\")\n",
    "super_graph = super_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa8fa4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "---\n",
       "config:\n",
       "  flowchart:\n",
       "    curve: linear\n",
       "---\n",
       "graph TD;\n",
       "\t__start__(<p>__start__</p>)\n",
       "\tsupervisor(supervisor)\n",
       "\tresearch_team(research_team)\n",
       "\twriting_team(writing_team)\n",
       "\t__end__(<p>__end__</p>)\n",
       "\t__start__ --> supervisor;\n",
       "\tsupervisor --> __end__;\n",
       "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
       "\tclassDef first fill-opacity:0\n",
       "\tclassDef last fill:#bfb6fc\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(f\"```mermaid\\n{super_graph.get_graph().draw_mermaid()}\\n```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9e1da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'research_team'}}\n",
      "---\n",
      "{'research_team': {'messages': [HumanMessage(content=\"Now I have enough information to compile a comprehensive report. Let me create a detailed analysis of the gold price increase in 2024.\\n\\n# Gold Price Increase Analysis Report 2024\\n\\n## Executive Summary\\n\\nGold prices experienced a significant surge in 2024, with prices rising approximately 27.23% throughout the year, reaching an all-time nominal high of $2,331 per troy ounce in April. This dramatic increase has been driven by a complex interplay of geopolitical uncertainties, central bank activities, inflation concerns, and shifting global economic dynamics.\\n\\n## Key Statistics\\n- **Price Increase**: ~27% increase in 2024\\n- **Peak Price**: $2,331 per troy ounce (April 2024)\\n- **Starting Price 2024**: $2,076 per troy ounce\\n- **Central Bank Purchases**: Over 1,000 tonnes for the third consecutive year\\n\\n## Primary Drivers of Gold Price Increases in 2024\\n\\n### 1. Central Bank Accumulation\\nThe most significant factor contributing to gold's price surge has been unprecedented central bank buying activity:\\n\\n- **Record Purchases**: Central banks accumulated over 1,000 tonnes of gold for the third consecutive year, a dramatic increase from the 400-500 tonne average of the preceding decade\\n- **Strategic Shift**: Nearly 70% of central banks plan to increase gold's share in their reserves over the next five years, according to a 2024 World Gold Council survey\\n- **De-dollarization Trend**: Countries are deliberately reducing their dependence on US dollar holdings in response to geopolitical tensions and financial sanctions\\n- **Key Players**: Emerging market central banks, particularly from countries geopolitically less aligned with the US, have been systematically increasing gold holdings for strategic independence\\n\\n### 2. Geopolitical Uncertainty and Safe-Haven Demand\\nMultiple geopolitical tensions have fueled gold's appeal as a safe-haven asset:\\n\\n- **Ongoing Conflicts**: Continued geopolitical tensions and conflicts have driven investors toward gold's stability\\n- **Trade Uncertainties**: International trade disputes and supply chain disruptions have increased economic uncertainty\\n- **Safe-Haven Premium**: Gold's price has incorporated a significant geopolitical risk premium throughout 2024\\n\\n### 3. Inflation and Currency Dynamics\\nMonetary policy and inflation concerns have played a crucial role:\\n\\n- **Inflation Hedge**: Gold has responded to persistent inflation concerns, with prices typically rising 1.5% for every 1% increase in inflation\\n- **US Dollar Weakness**: Persistent dollar weakness has made gold more attractive as an alternative store of value\\n- **Interest Rate Expectations**: Anticipation of Federal Reserve rate cuts and lower interest rate expectations have supported gold prices\\n\\n### 4. Investment Demand Surge\\nMultiple sources of investment demand have contributed to price increases:\\n\\n**ETF Activity**:\\n- Gold ETF investment broke records amid market volatility\\n- Significant inflows were concentrated in the second half of 2024\\n- Chinese ETF activity showed particularly strong growth\\n\\n**Bar and Coin Investment**:\\n- While physical bar and coin demand remained stable at 1,186 tonnes, the value surged 23% to a record $91 billion\\n- Q4 2024 saw a sharp pickup in demand as price dips presented buying opportunities\\n\\n### 5. Regional Demand Patterns\\n**Asian Market Dynamics**:\\n- China and India continue to dominate gold consumption\\n- India's total gold demand surpassed 800 tonnes in 2024\\n- China remains the largest market for total gold consumption, though India has overtaken China in some categories\\n- Growing middle class in emerging markets has spurred jewelry demand\\n\\n**Regional Variations**:\\n- US investment saw four consecutive quarters of year-over-year decline, reaching the lowest annual total since 2020\\n- Saudi Arabia, UAE, and Kuwait showed improved demand levels\\n- Some regions experienced market saturation and profit-taking\\n\\n### 6. Supply Chain and Production Factors\\nWhile less significant than demand factors, supply-side elements have contributed:\\n\\n- **Mining Production Constraints**: Higher mining costs and lower production levels in some regions\\n- **Supply Chain Disruptions**: Various supply chain issues affecting physical gold availability\\n- **Production Costs**: Increased mining costs have supported higher price floors\\n\\n## Market Outlook and Implications\\n\\n### Short-term Expectations\\n- Gold prices are expected to remain elevated, with continued support from central bank demand and geopolitical uncertainties\\n- Goldman Sachs projects potential price targets around $3,100 per troy ounce\\n- Continued robust demand from emerging market central banks is anticipated\\n\\n### Long-term Trends\\n- Structural shift toward gold as a reserve asset appears to be accelerating\\n- De-dollarization trend among emerging economies is likely to continue supporting gold demand\\n- Growing importance of gold as a geopolitical hedge rather than just an inflation hedge\\n\\n## Conclusion\\n\\nThe 2024 gold price surge represents a fundamental shift in how central banks and investors view gold's role in the global financial system. Unlike previous bull markets driven primarily by inflation concerns or jewelry demand, the current rally is characterized by strategic central bank accumulation, geopolitical risk management, and a broader de-dollarization trend. These factors suggest that gold's elevated price levels may be more sustainable than purely cyclical increases, as they reflect structural changes in global reserve management and risk assessment.\\n\\nThe combination of official sector demand, geopolitical uncertainty, and evolving monetary policy dynamics has created a robust foundation for gold prices, with the potential for continued strength as these underlying trends persist into 2025 and beyond.\", additional_kwargs={}, response_metadata={}, name='research_team', id='11a97b0e-2524-4114-9588-c20e93445cdb')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "  \"content\": \"Research why the gold price has been increasing recently (2024). Come up with the reasons and compile a report.\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\"recursion_limit\": 30}\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb6b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-learning (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
